from pathlib import Path
import os
import glob
from datetime import datetime

from dbetto import AttrsDict

from git import GitCommandError, InvalidGitRepositoryError, Repo

import hadesflow.methods.paths as paths
from hadesflow.methods.patterns import get_pattern_tier, get_pattern_tier_daq

from legenddataflowscripts.workflow import (
    pre_compile_catalog,
    execenv,
    subst_vars_in_snakemake_config,
)
from hadesflow.scripts.flow.build_filelist import get_filelist


envvars:
    "PRODENV",


os.environ["XDG_CACHE_HOME"] = config.get("XDG_CACHE_HOME", ".snakemake/cache")

subst_vars_in_snakemake_config(workflow, config)
config = AttrsDict(config)

check_in_cycle = True
dataflow_configs = paths.config_path(config)
basedir = workflow.basedir

# NOTE: this will attempt a clone of hades-metadata, if the directory does not exist
if not Path(dataflow_configs).exists() or not any(Path(dataflow_configs).iterdir()):
    Repo.clone_from(
        "git@github.com:legend-exp/hades-dataflow-config",
        dataflow_configs,
        multi_options=["--recurse-submodules"],
    )
if "hades_metadata_version" in config:
    Repo(dataflow_configs).git.checkout(config.hades_metadata_version)
    Repo(dataflow_configs).git.submodule("update", "--init")

time = datetime.now().strftime("%Y%m%dT%H%M%SZ")
dataflow_configs_texdb = pre_compile_catalog(Path(dataflow_configs))


wildcard_constraints:
    experiment=r"\w+",
    # detector=r"p\d{2}",
    # measurement=r"\w{3}",
    campaign=r"c\d+",
    run=r"r\d{3}",
    timestamp=r"\d{8}T\d{6}Z",


check_in_cycle = True


include: "rules/common.smk"
include: "rules/main.smk"
include: "rules/raw.smk"
include: "rules/dsp_pars.smk"
include: "rules/dsp.smk"
include: "rules/hit_pars.smk"
include: "rules/hit.smk"


localrules:
    gen_filelist,
    autogen_output,


onstart:
    print("Starting workflow")
    if not workflow.touch:
        shell(
            execenv.execenv_pyexe(config, "python")
            + "-c 'import lgdo, daq2lh5, matplotlib, pygama'"
        )
        shell(
            execenv.execenv_pyexe(config, "python")
            + "-c 'from dspeed.processors import *'"
        )


onsuccess:
    print("Workflow finished, no error")
    shell("rm *.gen || true")
    # shell(f"rm {filelist_path(setup)}/* || true")



# Placeholder, can email or maybe put message in slack
onerror:
    print("An error occurred :( ")


rule gen_filelist:
    """Generate file list.
    """
    input:
        lambda wildcards: get_filelist(
            wildcards,
            config,
            get_search_pattern(wildcards.tier),
            ignore_keys_file=Path(dataflow_configs) / "ignored_cycles.yaml",
        ),
    output:
        temp(Path(paths.filelist_path(config)) / "{label}-{tier}.filelist"),
    log:
        Path(paths.tmp_log_path(config)) / time / "filelists" / "{label}-{tier}.log",
    script:
        "src/hadesflow/scripts/flow/write_filelist.py"
